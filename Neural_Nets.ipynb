{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![CraigDoesData][logo]][link]\n",
    "\n",
    "[logo]: ./img/logo.png\n",
    "[link]: https://www.craigdoesdata.de/\n",
    "\n",
    "\n",
    "# Neural Networks\n",
    "Machine Learning training project utilising [TensorFlow](https://www.tensorflow.org/) to build a deep neural network model and make predictions.\n",
    "\n",
    "#### Project status - Complete\n",
    "\n",
    "## Introduction\n",
    "\n",
    "The intention of this project was to build a functioning neural network using [TensorFlow](https://www.tensorflow.org/), experiment with hidden layers and nodes and see the effect of other hyperparameters in the model.\n",
    "\n",
    "This was based on examples used in the excellent [Machine Learning Crash Course](https://developers.google.com/machine-learning/crash-course/ml-intro) offered by Google.\n",
    "\n",
    "\n",
    "\n",
    "### Methods used\n",
    "* EDA\n",
    "* Machine Learning\n",
    "* Deep Neural Networks\n",
    "* Loss Function Plotting\n",
    "* Gradient Descent\n",
    "* Activation Functions\n",
    "* Feature Engineering\n",
    "* Data visualisation\n",
    "\n",
    "### Technologies used\n",
    "* [Jupyter Notebook](https://jupyter.org/)\n",
    "* [NumPy](https://numpy.org)\n",
    "* [pandas](https://pandas.pydata.org/)\n",
    "* [TensorFlow](https://www.tensorflow.org/)\n",
    "* [Keras](https://keras.io/)\n",
    "* [Matplotlib](https://matplotlib.org/)\n",
    "\n",
    "### Data sources\n",
    "[California Housing Dataset](https://developers.google.com/machine-learning/crash-course/california-housing-data-description) based on the 1990 US Census. The data is at the 'block' level, so each record contains data for multiple houses or apartments.\n",
    "\n",
    "This is a familiar dataset for Machine Learning training, so apologies for the lack of originality! \n",
    "\n",
    "Sourced from [Google](https://download.mlcc.google.com/mledu-datasets/california_housing_train.csv).\n",
    "\n",
    "#### Features and Labels\n",
    "The [Label](https://pythonprogramming.net/features-labels-machine-learning-tutorial/) (the 'target' of our model, the attribute of the data that we want to output as a prediction when it is built) is median_house_value. The [features](https://pythonprogramming.net/features-labels-machine-learning-tutorial/) are the other attributes of the dataset, along with those we engineer from the given dataset features.\n",
    "\n",
    "As with all ML applications there are ethical considerations to take into account when selecting our features, and it is vital to keep this in mind. In this project the model will not be used for anything in the real world, so will not impact anyone negatively or positively, so we don't need to be too concerned about this at this stage.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "---------------------\n",
    "\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "#### 1. Import and Inspection\n",
    "* 1.1 Library Import\n",
    "* 1.2 Dataset Import\n",
    "* 1.3 Data Inspection\n",
    "* 1.4 Normalise Values\n",
    "\n",
    "#### 2. Feature Creation and Engineering\n",
    "* 2.1 Select features\n",
    "* 2.2 Bucketise Latitude and Longitude\n",
    "* 2.3 Create Feature Cross from Latitude and Longitude\n",
    "* 2.4 Convert Feature Columns to Feature Layer\n",
    "\n",
    "#### 3. Build Linear Regression Model as Baseline\n",
    "* 3.1 Define Loss Curve Plotting Function\n",
    "* 3.2 Define Model Creation and Training Functions\n",
    "* 3.3 Create and Train the Model using Linear Regression\n",
    "\n",
    "#### 4. Build Neural Network Model\n",
    "* 4.1 Define Model Creation Function\n",
    "* 4.2 Define Model Training Function\n",
    "* 4.3 Call the Functions - Build and Train a Deep Neural Net\n",
    "\n",
    "#### 5. Conclusion\n",
    "* 5.1 Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------\n",
    "\n",
    "### 1. Import and Inspection\n",
    "\n",
    "##### 1.1 - Library Import\n",
    "\n",
    "The first step is to import our libraries  ([NumPy](https://numpy.org/), [pandas](https://pandas.pydata.org/), [TensorFlow](https://www.tensorflow.org/), and [matplotlib.pyplot](https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.pyplot.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.2 - Dataset Import\n",
    "\n",
    "Now we import our dataset, the [California Housing Dataset](https://developers.google.com/machine-learning/crash-course/california-housing-data-description) based on the 1990 US Census. This has already been split into a training set and a test set, so we will import each into a [pandas](https://pandas.pydata.org/) [DataFrame](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html). \n",
    "\n",
    "The training set is also sorted by longitude - we will randomise the examples using NumPy so that this doesn't cause problems with training our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"https://download.mlcc.google.com/mledu-datasets/california_housing_train.csv\")\n",
    "train_df = train_df.reindex(np.random.permutation(train_df.index)) # randomise the examples\n",
    "test_df = pd.read_csv(\"https://download.mlcc.google.com/mledu-datasets/california_housing_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.3 - Data Inspection\n",
    "\n",
    "Let's use [.head()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.head.html) to see the first few rows of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2238</th>\n",
       "      <td>-117.40</td>\n",
       "      <td>33.85</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7538.0</td>\n",
       "      <td>1125.0</td>\n",
       "      <td>3450.0</td>\n",
       "      <td>1077.0</td>\n",
       "      <td>5.4625</td>\n",
       "      <td>223600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1442</th>\n",
       "      <td>-117.19</td>\n",
       "      <td>34.03</td>\n",
       "      <td>36.0</td>\n",
       "      <td>2223.0</td>\n",
       "      <td>361.0</td>\n",
       "      <td>942.0</td>\n",
       "      <td>331.0</td>\n",
       "      <td>4.6806</td>\n",
       "      <td>152400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15494</th>\n",
       "      <td>-122.32</td>\n",
       "      <td>37.94</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1911.0</td>\n",
       "      <td>283.0</td>\n",
       "      <td>697.0</td>\n",
       "      <td>275.0</td>\n",
       "      <td>6.2712</td>\n",
       "      <td>267700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16403</th>\n",
       "      <td>-122.55</td>\n",
       "      <td>38.02</td>\n",
       "      <td>27.0</td>\n",
       "      <td>4985.0</td>\n",
       "      <td>711.0</td>\n",
       "      <td>1928.0</td>\n",
       "      <td>742.0</td>\n",
       "      <td>6.4978</td>\n",
       "      <td>361500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14075</th>\n",
       "      <td>-122.06</td>\n",
       "      <td>40.02</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1435.0</td>\n",
       "      <td>277.0</td>\n",
       "      <td>690.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>2.3043</td>\n",
       "      <td>68400.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "2238     -117.40     33.85                 9.0       7538.0          1125.0   \n",
       "1442     -117.19     34.03                36.0       2223.0           361.0   \n",
       "15494    -122.32     37.94                47.0       1911.0           283.0   \n",
       "16403    -122.55     38.02                27.0       4985.0           711.0   \n",
       "14075    -122.06     40.02                32.0       1435.0           277.0   \n",
       "\n",
       "       population  households  median_income  median_house_value  \n",
       "2238       3450.0      1077.0         5.4625            223600.0  \n",
       "1442        942.0       331.0         4.6806            152400.0  \n",
       "15494       697.0       275.0         6.2712            267700.0  \n",
       "16403      1928.0       742.0         6.4978            361500.0  \n",
       "14075       690.0       254.0         2.3043             68400.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use [.describe()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.describe.html) to get descriptive statistics on all of the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>17000.000000</td>\n",
       "      <td>17000.000000</td>\n",
       "      <td>17000.000000</td>\n",
       "      <td>17000.000000</td>\n",
       "      <td>17000.000000</td>\n",
       "      <td>17000.000000</td>\n",
       "      <td>17000.000000</td>\n",
       "      <td>17000.000000</td>\n",
       "      <td>17000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-119.562108</td>\n",
       "      <td>35.625225</td>\n",
       "      <td>28.589353</td>\n",
       "      <td>2643.664412</td>\n",
       "      <td>539.410824</td>\n",
       "      <td>1429.573941</td>\n",
       "      <td>501.221941</td>\n",
       "      <td>3.883578</td>\n",
       "      <td>207300.912353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.005166</td>\n",
       "      <td>2.137340</td>\n",
       "      <td>12.586937</td>\n",
       "      <td>2179.947071</td>\n",
       "      <td>421.499452</td>\n",
       "      <td>1147.852959</td>\n",
       "      <td>384.520841</td>\n",
       "      <td>1.908157</td>\n",
       "      <td>115983.764387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-124.350000</td>\n",
       "      <td>32.540000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.499900</td>\n",
       "      <td>14999.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-121.790000</td>\n",
       "      <td>33.930000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1462.000000</td>\n",
       "      <td>297.000000</td>\n",
       "      <td>790.000000</td>\n",
       "      <td>282.000000</td>\n",
       "      <td>2.566375</td>\n",
       "      <td>119400.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-118.490000</td>\n",
       "      <td>34.250000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>2127.000000</td>\n",
       "      <td>434.000000</td>\n",
       "      <td>1167.000000</td>\n",
       "      <td>409.000000</td>\n",
       "      <td>3.544600</td>\n",
       "      <td>180400.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-118.000000</td>\n",
       "      <td>37.720000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>3151.250000</td>\n",
       "      <td>648.250000</td>\n",
       "      <td>1721.000000</td>\n",
       "      <td>605.250000</td>\n",
       "      <td>4.767000</td>\n",
       "      <td>265000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>-114.310000</td>\n",
       "      <td>41.950000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>37937.000000</td>\n",
       "      <td>6445.000000</td>\n",
       "      <td>35682.000000</td>\n",
       "      <td>6082.000000</td>\n",
       "      <td>15.000100</td>\n",
       "      <td>500001.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          longitude      latitude  housing_median_age   total_rooms  \\\n",
       "count  17000.000000  17000.000000        17000.000000  17000.000000   \n",
       "mean    -119.562108     35.625225           28.589353   2643.664412   \n",
       "std        2.005166      2.137340           12.586937   2179.947071   \n",
       "min     -124.350000     32.540000            1.000000      2.000000   \n",
       "25%     -121.790000     33.930000           18.000000   1462.000000   \n",
       "50%     -118.490000     34.250000           29.000000   2127.000000   \n",
       "75%     -118.000000     37.720000           37.000000   3151.250000   \n",
       "max     -114.310000     41.950000           52.000000  37937.000000   \n",
       "\n",
       "       total_bedrooms    population    households  median_income  \\\n",
       "count    17000.000000  17000.000000  17000.000000   17000.000000   \n",
       "mean       539.410824   1429.573941    501.221941       3.883578   \n",
       "std        421.499452   1147.852959    384.520841       1.908157   \n",
       "min          1.000000      3.000000      1.000000       0.499900   \n",
       "25%        297.000000    790.000000    282.000000       2.566375   \n",
       "50%        434.000000   1167.000000    409.000000       3.544600   \n",
       "75%        648.250000   1721.000000    605.250000       4.767000   \n",
       "max       6445.000000  35682.000000   6082.000000      15.000100   \n",
       "\n",
       "       median_house_value  \n",
       "count        17000.000000  \n",
       "mean        207300.912353  \n",
       "std         115983.764387  \n",
       "min          14999.000000  \n",
       "25%         119400.000000  \n",
       "50%         180400.000000  \n",
       "75%         265000.000000  \n",
       "max         500001.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have an idea of the contents of the dataset in its original state, we can move on to normalising the values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.4 - Normalise values\n",
    "\n",
    "The next step is to normalise the values across our DataFrames. This helps prevent the calculations involved in running our Neural Net from getting out of hand and potentially [overflowing](https://levelup.gitconnected.com/what-is-overflow-5a2f36d17dc7).\n",
    "\n",
    "We will use the [z-score](https://www.statisticshowto.com/probability-and-statistics/z-score/) to normalise our values, but there are numerous effective alternative ways to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the Z-scores of each column in the training set:\n",
    "train_df_mean = train_df.mean()\n",
    "train_df_std = train_df.std()\n",
    "train_df_norm = (train_df - train_df_mean)/train_df_std\n",
    "\n",
    "# Calculate the Z-scores of each column in the test set.\n",
    "test_df_mean = test_df.mean()\n",
    "test_df_std = test_df.std()\n",
    "test_df_norm = (test_df - test_df_mean)/test_df_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------\n",
    "\n",
    "### 2. Feature Creation and Engineering\n",
    "\n",
    "##### 2.1 - Select features.\n",
    "\n",
    "We are building a relatively simple neural network here, so will use a fairly limited set of features. The first features we are going to use are:\n",
    "\n",
    "* Median Income\n",
    "* Population\n",
    "\n",
    "Median Income and Population are two features which are likely to have a significant impact on the value of a property. As this is what we are building a model to predict, the label for our model, these will make good choices for features.\n",
    "\n",
    "In the following code we convert these into floating-point values for the benefit of TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list that will eventually hold all created feature columns.\n",
    "feature_columns = []\n",
    "\n",
    "\n",
    "# Represent median_income as a floating-point value.\n",
    "median_income = tf.feature_column.numeric_column(\"median_income\")\n",
    "feature_columns.append(median_income)\n",
    "\n",
    "# Represent population as a floating-point value.\n",
    "population = tf.feature_column.numeric_column(\"population\")\n",
    "feature_columns.append(population)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are building a value prediction model for real estate. What are the three most important things in determining the value of any property? [Location, Location, Location](https://en.wikipedia.org/wiki/Location,_Location,_Location)! \n",
    "\n",
    "\n",
    "##### 2.2 - Bucketise Latitude and Longitude\n",
    "\n",
    "Our dataset contains latitude and longitude data for each block. We could use each of these one-dimensional columns as a feature on their own, but they will be more powerful if we convert them into a 2-dimensional array using [feature crossing](https://developers.google.com/machine-learning/crash-course/feature-crosses/video-lecture). This will allow our model to use more precise location data, learn more quickly and (hopefully) produce more accurate predictions.\n",
    "\n",
    "The first step here is to ['bucketise'](https://en.wikipedia.org/wiki/Data_binning) the latitude and longitude into discrete buckets, instead of using these as a continuous variable. To do this we need to define a resolution for our buckets (not forgetting that our data has been normlaised into z-scores). We arbitrarily use 0.3 Zs as this resolution - other values here might affect the quality of our model, feel free to explore the effect this will have if you have time to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "resolution_in_Zs = 0.3  # 3/10 of a standard deviation.\n",
    "\n",
    "# Create a bucket feature column for latitude.\n",
    "latitude_as_a_numeric_column = tf.feature_column.numeric_column(\"latitude\")\n",
    "latitude_boundaries = list(np.arange(int(min(train_df_norm['latitude'])), \n",
    "                                     int(max(train_df_norm['latitude'])), \n",
    "                                     resolution_in_Zs))\n",
    "latitude = tf.feature_column.bucketized_column(latitude_as_a_numeric_column, latitude_boundaries)\n",
    "\n",
    "# Create a bucket feature column for longitude.\n",
    "longitude_as_a_numeric_column = tf.feature_column.numeric_column(\"longitude\")\n",
    "longitude_boundaries = list(np.arange(int(min(train_df_norm['longitude'])), \n",
    "                                      int(max(train_df_norm['longitude'])), \n",
    "                                      resolution_in_Zs))\n",
    "longitude = tf.feature_column.bucketized_column(longitude_as_a_numeric_column, \n",
    "                                                longitude_boundaries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3 - Create Feature Cross from Latitude and Longitude\n",
    "\n",
    "The next step is to use [crossed_column](https://www.tensorflow.org/api_docs/python/tf/feature_column/crossed_column) to combine these two bucketised columns, and add our new crossed feature to our list of feature_columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a feature cross of latitude and longitude.\n",
    "latitude_x_longitude = tf.feature_column.crossed_column([latitude, longitude], hash_bucket_size=100)\n",
    "crossed_feature = tf.feature_column.indicator_column(latitude_x_longitude)\n",
    "feature_columns.append(crossed_feature)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.4 - Convert Feature Columns to Feature Layer\n",
    "\n",
    "The final step here is to use the [Keras API](https://www.tensorflow.org/guide/keras/sequential_model) to convert our feature_columns list into a feature_layer for use in our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_feature_layer = tf.keras.layers.DenseFeatures(feature_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------\n",
    "\n",
    "### 3. Build Linear Regression Model as Baseline\n",
    "\n",
    "In order to guage the effectiveness of the neural net approach we are going to take, it is helpful to build a Linear Regression model using the same feature layer so that we have a baseline for comparison. The following functions are taken directly from the [Machine Learning Crash Course](https://developers.google.com/machine-learning/crash-course/ml-intro).\n",
    "\n",
    "If you want to skip ahead to the neural net section, just run the next cell (Define Loss Plotting Function) and then head to Section 4.\n",
    "\n",
    "\n",
    "##### 3.1 - Define Loss Curve Plotting Function\n",
    "\n",
    "This code defines a [Matplotlib](https://matplotlib.org/) function to visualise the Loss Curve of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_the_loss_curve(epochs, mse):\n",
    "  \"\"\"Plot a curve of loss vs. epoch.\"\"\"\n",
    "\n",
    "  plt.figure()\n",
    "  plt.xlabel(\"Epoch\")\n",
    "  plt.ylabel(\"Mean Squared Error\")\n",
    "\n",
    "  plt.plot(epochs, mse, label=\"Loss\")\n",
    "  plt.legend()\n",
    "  plt.ylim([mse.min()*0.95, mse.max() * 1.03])\n",
    "  plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.2 - Define Model Creation and Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(my_learning_rate, feature_layer):\n",
    "  \"\"\"Create and compile a simple linear regression model.\"\"\"\n",
    "  # Most simple tf.keras models are sequential.\n",
    "  model = tf.keras.models.Sequential()\n",
    "\n",
    "  # Add the layer containing the feature columns to the model.\n",
    "  model.add(feature_layer)\n",
    "\n",
    "  # Add one linear layer to the model to yield a simple linear regressor.\n",
    "  model.add(tf.keras.layers.Dense(units=1, input_shape=(1,)))\n",
    "\n",
    "  # Construct the layers into a model that TensorFlow can execute.\n",
    "  model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=my_learning_rate),\n",
    "                loss=\"mean_squared_error\",\n",
    "                metrics=[tf.keras.metrics.MeanSquaredError()])\n",
    "\n",
    "  return model           \n",
    "\n",
    "\n",
    "def train_model(model, dataset, epochs, batch_size, label_name):\n",
    "  \"\"\"Feed a dataset into the model in order to train it.\"\"\"\n",
    "\n",
    "  # Split the dataset into features and label.\n",
    "  features = {name:np.array(value) for name, value in dataset.items()}\n",
    "  label = np.array(features.pop(label_name))\n",
    "  history = model.fit(x=features, y=label, batch_size=batch_size,\n",
    "                      epochs=epochs, shuffle=True)\n",
    "\n",
    "  # Get details that will be useful for plotting the loss curve.\n",
    "  epochs = history.epoch\n",
    "  hist = pd.DataFrame(history.history)\n",
    "  rmse = hist[\"mean_squared_error\"]\n",
    "\n",
    "  return epochs, rmse   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.3 - Create and Train the Model using Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\info\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\feature_column\\feature_column_v2.py:4267: IndicatorColumn._variable_shape (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "WARNING:tensorflow:From C:\\Users\\info\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\feature_column\\feature_column_v2.py:4322: CrossedColumn._num_buckets (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "Train on 17000 samples\n",
      "Epoch 1/15\n",
      "17000/17000 [==============================] - 1s 72us/sample - loss: 0.7021 - mean_squared_error: 0.7021\n",
      "Epoch 2/15\n",
      "17000/17000 [==============================] - 0s 5us/sample - loss: 0.4949 - mean_squared_error: 0.4949\n",
      "Epoch 3/15\n",
      "17000/17000 [==============================] - 0s 5us/sample - loss: 0.4113 - mean_squared_error: 0.4113\n",
      "Epoch 4/15\n",
      "17000/17000 [==============================] - 0s 6us/sample - loss: 0.3770 - mean_squared_error: 0.3770\n",
      "Epoch 5/15\n",
      "17000/17000 [==============================] - 0s 6us/sample - loss: 0.3659 - mean_squared_error: 0.3659\n",
      "Epoch 6/15\n",
      "17000/17000 [==============================] - 0s 10us/sample - loss: 0.3624 - mean_squared_error: 0.3624\n",
      "Epoch 7/15\n",
      "17000/17000 [==============================] - 0s 9us/sample - loss: 0.3611 - mean_squared_error: 0.3611\n",
      "Epoch 8/15\n",
      "17000/17000 [==============================] - 0s 8us/sample - loss: 0.3604 - mean_squared_error: 0.3604\n",
      "Epoch 9/15\n",
      "17000/17000 [==============================] - 0s 9us/sample - loss: 0.3603 - mean_squared_error: 0.3603\n",
      "Epoch 10/15\n",
      "17000/17000 [==============================] - 0s 7us/sample - loss: 0.3600 - mean_squared_error: 0.3600\n",
      "Epoch 11/15\n",
      "17000/17000 [==============================] - 0s 7us/sample - loss: 0.3599 - mean_squared_error: 0.3599\n",
      "Epoch 12/15\n",
      "17000/17000 [==============================] - 0s 7us/sample - loss: 0.3598 - mean_squared_error: 0.3598\n",
      "Epoch 13/15\n",
      "17000/17000 [==============================] - 0s 7us/sample - loss: 0.3600 - mean_squared_error: 0.3600\n",
      "Epoch 14/15\n",
      "17000/17000 [==============================] - 0s 6us/sample - loss: 0.3599 - mean_squared_error: 0.3599\n",
      "Epoch 15/15\n",
      "17000/17000 [==============================] - 0s 6us/sample - loss: 0.3597 - mean_squared_error: 0.3597\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Evaluate the linear regression model against the test set:\n",
      "3000/3000 [==============================] - 0s 157us/sample - loss: 0.3955 - mean_squared_error: 0.3955\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.395509531100591, 0.3955095]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_rate = 0.01\n",
    "epochs = 15\n",
    "batch_size = 1000\n",
    "label_name = \"median_house_value\"\n",
    "\n",
    "# Establish the model's topography.\n",
    "my_model = create_model(learning_rate, my_feature_layer)\n",
    "\n",
    "# Train the model on the normalized training set.\n",
    "epochs, mse = train_model(my_model, train_df_norm, epochs, batch_size, label_name)\n",
    "plot_the_loss_curve(epochs, mse)\n",
    "\n",
    "test_features = {name:np.array(value) for name, value in test_df_norm.items()}\n",
    "test_label = np.array(test_features.pop(label_name)) # isolate the label\n",
    "print(\"\\n Evaluate the linear regression model against the test set:\")\n",
    "my_model.evaluate(x = test_features, y = test_label, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us a baseline of around 0.395 against the test set. This is useful data for assessing our neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------\n",
    "### 4. Build Neural Network Model\n",
    "\n",
    "Now we will move on to the main part of this project - creating and training a neural net using TensorFlow that we can then use to make predictions for house values.\n",
    "\n",
    "##### 4.1 - Define Model Creation Function\n",
    "\n",
    "The code below creates a function which we can run as often as required to create a neural network in TensorFlow. We are going to take advantage of the [Keras API](https://www.tensorflow.org/guide/keras/sequential_model) which comes bundled with TensorFlow - this makes building a neural netowrk about as simple as building a neural network can be.\n",
    "\n",
    "The Sequential model effectively works by letting us define as many layers as we want, and then compiling them together to create a model which we can use.\n",
    "\n",
    "In this example we first declare our model. The next step is to use [model.add](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential) to add our feature layer, which we created back in step 2.4.\n",
    "\n",
    "After this we want to define the topography of the model, again using model.add. In this case we add two [Dense layers](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense), and specify how many units are in the layer and the [activation function](https://www.tensorflow.org/api_docs/python/tf/keras/activations) (in this case a [rectified linear unit](https://www.tensorflow.org/api_docs/python/tf/keras/activations/relu), one of the simpler possibilities), and a name string which is useful for debugging.\n",
    "\n",
    "We could also add some [regularisation](https://towardsdatascience.com/l1-and-l2-regularization-methods-ce25e7fc831c) to penalise complexity (and act against overfitting) at this stage, however in my experiments these had a net negative effect on the evaluation of the model against the test set.\n",
    "\n",
    "Next we add one final 'output' layer to our model, and finally we [compile](https://www.tensorflow.org/api_docs/python/tf/keras/Model#compile) the model and return it as the output of the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(my_learning_rate, my_feature_layer):\n",
    "  \"\"\"Create and compile a simple neural network model.\"\"\"\n",
    "\n",
    "  # Discard any pre-existing version of the model.\n",
    "  model = None\n",
    "    \n",
    "  # Most simple tf.keras models are sequential.\n",
    "  model = tf.keras.models.Sequential()\n",
    "\n",
    "  # Add the layer containing the feature columns to the model.\n",
    "  model.add(my_feature_layer)\n",
    "\n",
    "  # Describe the topography of the model by calling the tf.keras.layers.Dense\n",
    "  # method once for each layer.\n",
    "\n",
    "  # Define the first hidden layer with 20 nodes.   \n",
    "  model.add(tf.keras.layers.Dense(units=20, \n",
    "                                  activation='relu', \n",
    "                                  name='Hidden1'))\n",
    "  \n",
    "  # Define the second hidden layer with 12 nodes. \n",
    "  model.add(tf.keras.layers.Dense(units=12, \n",
    "                                  activation='relu', \n",
    "                                  name='Hidden2'))\n",
    "  \n",
    "  # Define the output layer.\n",
    "  model.add(tf.keras.layers.Dense(units=1,  \n",
    "                                  name='Output'))                              \n",
    "  \n",
    "  model.compile(optimizer=tf.keras.optimizers.Adam(lr=my_learning_rate),\n",
    "                loss=\"mean_squared_error\",\n",
    "                metrics=[tf.keras.metrics.MeanSquaredError()])\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.2 - Define Model Training Function\n",
    "\n",
    "Now the function which defines our model is created, the next step is to define a function to train the model by 'feeding' it data.\n",
    "\n",
    "Here we loop through the dataset, converting each column of our DataFrame into a NumPy array and adding them to the list called features. Then we [pop](https://www.programiz.com/python-programming/methods/list/pop) our chosen label (entered as an argument to the train_model function) out of the list, so we have the label and features as separate variables.\n",
    "\n",
    "These then are fed into [model.fit](https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit) to learn the model. \n",
    "\n",
    "The remainder of the function tracks the course of the training so that we can visualise it and confirm that the model is learning over the course of the epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataset, epochs, label_name,\n",
    "                batch_size=None):\n",
    "  \"\"\"Train the model by feeding it data.\"\"\"\n",
    "\n",
    "  # Split the dataset into features and label.\n",
    "  features = {name:np.array(value) for name, value in dataset.items()}\n",
    "  label = np.array(features.pop(label_name))\n",
    "  history = model.fit(x=features, y=label, batch_size=batch_size,\n",
    "                      epochs=epochs, shuffle=True) \n",
    "\n",
    "  # The list of epochs is stored separately from the rest of history.\n",
    "  epochs = history.epoch\n",
    "  \n",
    "  # To track the progression of training, gather a snapshot\n",
    "  # of the model's mean squared error at each epoch. \n",
    "  hist = pd.DataFrame(history.history)\n",
    "  mse = hist[\"mean_squared_error\"]\n",
    "\n",
    "  return epochs, mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.3 - Call the Functions - Build and Train a Deep Neural Net\n",
    "\n",
    "The next step is to define our [hyperparameters](https://en.wikipedia.org/wiki/Hyperparameter_optimization) (tuning these is the main trial-and-error art of building a good model). \n",
    "\n",
    "We specify our label, then call the functions with the appropriate arguments.\n",
    "\n",
    "Once the model has been trained against the training set, the final piece of code in this block tests the model against the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17000 samples\n",
      "Epoch 1/140\n",
      "17000/17000 [==============================] - 1s 81us/sample - loss: 0.6366 - mean_squared_error: 0.6366\n",
      "Epoch 2/140\n",
      "17000/17000 [==============================] - 0s 8us/sample - loss: 0.3810 - mean_squared_error: 0.3810\n",
      "Epoch 3/140\n",
      "17000/17000 [==============================] - 0s 8us/sample - loss: 0.3449 - mean_squared_error: 0.3449\n",
      "Epoch 4/140\n",
      "17000/17000 [==============================] - 0s 8us/sample - loss: 0.3378 - mean_squared_error: 0.3378\n",
      "Epoch 5/140\n",
      "17000/17000 [==============================] - 0s 9us/sample - loss: 0.3349 - mean_squared_error: 0.3349\n",
      "Epoch 6/140\n",
      "17000/17000 [==============================] - 0s 8us/sample - loss: 0.3332 - mean_squared_error: 0.3332\n",
      "Epoch 7/140\n",
      "17000/17000 [==============================] - 0s 8us/sample - loss: 0.3320 - mean_squared_error: 0.3320\n",
      "Epoch 8/140\n",
      "17000/17000 [==============================] - 0s 8us/sample - loss: 0.3311 - mean_squared_error: 0.3311\n",
      "Epoch 9/140\n",
      "17000/17000 [==============================] - 0s 8us/sample - loss: 0.3308 - mean_squared_error: 0.3308\n",
      "Epoch 10/140\n",
      "17000/17000 [==============================] - 0s 8us/sample - loss: 0.3301 - mean_squared_error: 0.3301\n",
      "Epoch 11/140\n",
      "17000/17000 [==============================] - 0s 11us/sample - loss: 0.3300 - mean_squared_error: 0.3300\n",
      "Epoch 12/140\n",
      "17000/17000 [==============================] - 0s 10us/sample - loss: 0.3285 - mean_squared_error: 0.3285\n",
      "Epoch 13/140\n",
      "17000/17000 [==============================] - 0s 10us/sample - loss: 0.3281 - mean_squared_error: 0.3281\n",
      "Epoch 14/140\n",
      "17000/17000 [==============================] - 0s 9us/sample - loss: 0.3266 - mean_squared_error: 0.3266\n",
      "Epoch 15/140\n",
      "17000/17000 [==============================] - 0s 12us/sample - loss: 0.3278 - mean_squared_error: 0.3278\n",
      "Epoch 16/140\n",
      "17000/17000 [==============================] - 0s 13us/sample - loss: 0.3272 - mean_squared_error: 0.3272\n",
      "Epoch 17/140\n",
      "17000/17000 [==============================] - 0s 13us/sample - loss: 0.3252 - mean_squared_error: 0.3252\n",
      "Epoch 18/140\n",
      "17000/17000 [==============================] - 0s 12us/sample - loss: 0.3242 - mean_squared_error: 0.3242\n",
      "Epoch 19/140\n",
      "17000/17000 [==============================] - 0s 12us/sample - loss: 0.3243 - mean_squared_error: 0.3243\n",
      "Epoch 20/140\n",
      "17000/17000 [==============================] - 0s 12us/sample - loss: 0.3263 - mean_squared_error: 0.3263\n",
      "Epoch 21/140\n",
      "17000/17000 [==============================] - 0s 10us/sample - loss: 0.3242 - mean_squared_error: 0.3242\n",
      "Epoch 22/140\n",
      "17000/17000 [==============================] - 0s 12us/sample - loss: 0.3255 - mean_squared_error: 0.3255\n",
      "Epoch 23/140\n",
      "17000/17000 [==============================] - 0s 9us/sample - loss: 0.3240 - mean_squared_error: 0.3240\n",
      "Epoch 24/140\n",
      "17000/17000 [==============================] - 0s 9us/sample - loss: 0.3227 - mean_squared_error: 0.3227\n",
      "Epoch 25/140\n",
      "17000/17000 [==============================] - 0s 8us/sample - loss: 0.3227 - mean_squared_error: 0.3227\n",
      "Epoch 26/140\n",
      "17000/17000 [==============================] - 0s 9us/sample - loss: 0.3221 - mean_squared_error: 0.3221\n",
      "Epoch 27/140\n",
      "17000/17000 [==============================] - 0s 8us/sample - loss: 0.3231 - mean_squared_error: 0.3231\n",
      "Epoch 28/140\n",
      "17000/17000 [==============================] - 0s 9us/sample - loss: 0.3224 - mean_squared_error: 0.3224\n",
      "Epoch 29/140\n",
      "17000/17000 [==============================] - 0s 8us/sample - loss: 0.3240 - mean_squared_error: 0.3240\n",
      "Epoch 30/140\n",
      "17000/17000 [==============================] - 0s 12us/sample - loss: 0.3235 - mean_squared_error: 0.3235\n",
      "Epoch 31/140\n",
      "17000/17000 [==============================] - 0s 13us/sample - loss: 0.3216 - mean_squared_error: 0.3216\n",
      "Epoch 32/140\n",
      "17000/17000 [==============================] - 0s 11us/sample - loss: 0.3211 - mean_squared_error: 0.3211\n",
      "Epoch 33/140\n",
      "17000/17000 [==============================] - 0s 12us/sample - loss: 0.3215 - mean_squared_error: 0.3215\n",
      "Epoch 34/140\n",
      "17000/17000 [==============================] - 0s 10us/sample - loss: 0.3215 - mean_squared_error: 0.3215\n",
      "Epoch 35/140\n",
      "17000/17000 [==============================] - 0s 9us/sample - loss: 0.3218 - mean_squared_error: 0.3218\n",
      "Epoch 36/140\n",
      "17000/17000 [==============================] - 0s 9us/sample - loss: 0.3206 - mean_squared_error: 0.3206\n",
      "Epoch 37/140\n",
      "17000/17000 [==============================] - 0s 8us/sample - loss: 0.3203 - mean_squared_error: 0.3203\n",
      "Epoch 38/140\n",
      "17000/17000 [==============================] - 0s 10us/sample - loss: 0.3214 - mean_squared_error: 0.3214\n",
      "Epoch 39/140\n",
      "17000/17000 [==============================] - 0s 11us/sample - loss: 0.3212 - mean_squared_error: 0.3212s - loss: 0.3217 - mean_squared_error: \n",
      "Epoch 40/140\n",
      "17000/17000 [==============================] - 0s 10us/sample - loss: 0.3207 - mean_squared_error: 0.3207\n",
      "Epoch 41/140\n",
      "17000/17000 [==============================] - 0s 9us/sample - loss: 0.3199 - mean_squared_error: 0.3199\n",
      "Epoch 42/140\n",
      "17000/17000 [==============================] - 0s 9us/sample - loss: 0.3214 - mean_squared_error: 0.3214\n",
      "Epoch 43/140\n",
      "17000/17000 [==============================] - 0s 8us/sample - loss: 0.3209 - mean_squared_error: 0.3209\n",
      "Epoch 44/140\n",
      "17000/17000 [==============================] - 0s 8us/sample - loss: 0.3205 - mean_squared_error: 0.3205\n",
      "Epoch 45/140\n",
      "17000/17000 [==============================] - 0s 11us/sample - loss: 0.3201 - mean_squared_error: 0.3201\n",
      "Epoch 46/140\n",
      "17000/17000 [==============================] - 0s 10us/sample - loss: 0.3197 - mean_squared_error: 0.3197\n",
      "Epoch 47/140\n",
      "17000/17000 [==============================] - 0s 13us/sample - loss: 0.3204 - mean_squared_error: 0.3204\n",
      "Epoch 48/140\n",
      "17000/17000 [==============================] - 0s 10us/sample - loss: 0.3214 - mean_squared_error: 0.3214\n",
      "Epoch 49/140\n",
      "17000/17000 [==============================] - 0s 14us/sample - loss: 0.3216 - mean_squared_error: 0.3216s - loss: 0.3236 - mean_squared_error: 0.\n",
      "Epoch 50/140\n",
      "17000/17000 [==============================] - 0s 10us/sample - loss: 0.3199 - mean_squared_error: 0.3199\n",
      "Epoch 51/140\n",
      "17000/17000 [==============================] - 0s 11us/sample - loss: 0.3220 - mean_squared_error: 0.3220\n",
      "Epoch 52/140\n",
      "17000/17000 [==============================] - 0s 14us/sample - loss: 0.3194 - mean_squared_error: 0.3194\n",
      "Epoch 53/140\n",
      "17000/17000 [==============================] - 0s 15us/sample - loss: 0.3187 - mean_squared_error: 0.3187\n",
      "Epoch 54/140\n",
      "17000/17000 [==============================] - 0s 14us/sample - loss: 0.3185 - mean_squared_error: 0.3185\n",
      "Epoch 55/140\n",
      "17000/17000 [==============================] - 0s 9us/sample - loss: 0.3176 - mean_squared_error: 0.3176\n",
      "Epoch 56/140\n",
      "17000/17000 [==============================] - 0s 8us/sample - loss: 0.3192 - mean_squared_error: 0.3192\n",
      "Epoch 57/140\n",
      "17000/17000 [==============================] - 0s 8us/sample - loss: 0.3182 - mean_squared_error: 0.3182\n",
      "Epoch 58/140\n",
      "17000/17000 [==============================] - 0s 9us/sample - loss: 0.3187 - mean_squared_error: 0.3187\n",
      "Epoch 59/140\n",
      "17000/17000 [==============================] - 0s 9us/sample - loss: 0.3186 - mean_squared_error: 0.3186\n",
      "Epoch 60/140\n",
      "17000/17000 [==============================] - 0s 10us/sample - loss: 0.3191 - mean_squared_error: 0.3191\n",
      "Epoch 61/140\n",
      "17000/17000 [==============================] - 0s 11us/sample - loss: 0.3184 - mean_squared_error: 0.3184\n",
      "Epoch 62/140\n",
      "17000/17000 [==============================] - 0s 8us/sample - loss: 0.3179 - mean_squared_error: 0.3179\n",
      "Epoch 63/140\n",
      "17000/17000 [==============================] - 0s 8us/sample - loss: 0.3174 - mean_squared_error: 0.3174\n",
      "Epoch 64/140\n",
      "17000/17000 [==============================] - 0s 9us/sample - loss: 0.3176 - mean_squared_error: 0.3176\n",
      "Epoch 65/140\n",
      "17000/17000 [==============================] - 0s 9us/sample - loss: 0.3179 - mean_squared_error: 0.3179\n",
      "Epoch 66/140\n",
      "17000/17000 [==============================] - 0s 8us/sample - loss: 0.3183 - mean_squared_error: 0.3183\n",
      "Epoch 67/140\n",
      "17000/17000 [==============================] - 0s 9us/sample - loss: 0.3181 - mean_squared_error: 0.3181\n",
      "Epoch 68/140\n",
      "17000/17000 [==============================] - 0s 11us/sample - loss: 0.3173 - mean_squared_error: 0.3173\n",
      "Epoch 69/140\n",
      "17000/17000 [==============================] - 0s 10us/sample - loss: 0.3193 - mean_squared_error: 0.3193\n",
      "Epoch 70/140\n",
      "17000/17000 [==============================] - 0s 10us/sample - loss: 0.3215 - mean_squared_error: 0.3215\n",
      "Epoch 71/140\n",
      "17000/17000 [==============================] - 0s 10us/sample - loss: 0.3187 - mean_squared_error: 0.3187\n",
      "Epoch 72/140\n",
      "17000/17000 [==============================] - 0s 9us/sample - loss: 0.3169 - mean_squared_error: 0.3169\n",
      "Epoch 73/140\n",
      "17000/17000 [==============================] - 0s 9us/sample - loss: 0.3164 - mean_squared_error: 0.3164\n",
      "Epoch 74/140\n",
      "17000/17000 [==============================] - 0s 8us/sample - loss: 0.3170 - mean_squared_error: 0.3170\n",
      "Epoch 75/140\n",
      "17000/17000 [==============================] - 0s 8us/sample - loss: 0.3169 - mean_squared_error: 0.3169\n",
      "Epoch 76/140\n",
      "17000/17000 [==============================] - 0s 9us/sample - loss: 0.3169 - mean_squared_error: 0.3169\n",
      "Epoch 77/140\n",
      "17000/17000 [==============================] - 0s 8us/sample - loss: 0.3159 - mean_squared_error: 0.3159\n",
      "Epoch 78/140\n",
      "17000/17000 [==============================] - 0s 9us/sample - loss: 0.3163 - mean_squared_error: 0.3163\n",
      "Epoch 79/140\n",
      "17000/17000 [==============================] - 0s 9us/sample - loss: 0.3155 - mean_squared_error: 0.3155\n",
      "Epoch 80/140\n",
      "17000/17000 [==============================] - 0s 8us/sample - loss: 0.3159 - mean_squared_error: 0.3159\n",
      "Epoch 81/140\n",
      "17000/17000 [==============================] - 0s 8us/sample - loss: 0.3153 - mean_squared_error: 0.3153\n",
      "Epoch 82/140\n",
      "17000/17000 [==============================] - 0s 8us/sample - loss: 0.3150 - mean_squared_error: 0.3150\n",
      "Epoch 83/140\n",
      "17000/17000 [==============================] - 0s 8us/sample - loss: 0.3171 - mean_squared_error: 0.3171\n",
      "Epoch 84/140\n",
      "17000/17000 [==============================] - 0s 9us/sample - loss: 0.3173 - mean_squared_error: 0.3173\n",
      "Epoch 85/140\n",
      "17000/17000 [==============================] - 0s 7us/sample - loss: 0.3153 - mean_squared_error: 0.3153\n",
      "Epoch 86/140\n",
      "17000/17000 [==============================] - 0s 8us/sample - loss: 0.3151 - mean_squared_error: 0.3151\n",
      "Epoch 87/140\n",
      "17000/17000 [==============================] - 0s 10us/sample - loss: 0.3168 - mean_squared_error: 0.3168\n",
      "Epoch 88/140\n",
      "17000/17000 [==============================] - 0s 14us/sample - loss: 0.3163 - mean_squared_error: 0.3163\n",
      "Epoch 89/140\n",
      "17000/17000 [==============================] - 0s 15us/sample - loss: 0.3167 - mean_squared_error: 0.3167\n",
      "Epoch 90/140\n",
      "17000/17000 [==============================] - 0s 12us/sample - loss: 0.3165 - mean_squared_error: 0.3165\n",
      "Epoch 91/140\n",
      "17000/17000 [==============================] - 0s 12us/sample - loss: 0.3157 - mean_squared_error: 0.3157\n",
      "Epoch 92/140\n",
      "17000/17000 [==============================] - 0s 10us/sample - loss: 0.3160 - mean_squared_error: 0.3160\n",
      "Epoch 93/140\n",
      "17000/17000 [==============================] - 0s 9us/sample - loss: 0.3169 - mean_squared_error: 0.3169\n",
      "Epoch 94/140\n",
      "17000/17000 [==============================] - 0s 9us/sample - loss: 0.3160 - mean_squared_error: 0.3160\n",
      "Epoch 95/140\n",
      "17000/17000 [==============================] - 0s 10us/sample - loss: 0.3152 - mean_squared_error: 0.3152\n",
      "Epoch 96/140\n",
      "17000/17000 [==============================] - 0s 9us/sample - loss: 0.3150 - mean_squared_error: 0.3150\n",
      "Epoch 97/140\n",
      "17000/17000 [==============================] - 0s 8us/sample - loss: 0.3151 - mean_squared_error: 0.3151\n",
      "Epoch 98/140\n",
      "17000/17000 [==============================] - 0s 9us/sample - loss: 0.3156 - mean_squared_error: 0.3156\n",
      "Epoch 99/140\n",
      "17000/17000 [==============================] - 0s 8us/sample - loss: 0.3153 - mean_squared_error: 0.3153\n",
      "Epoch 100/140\n",
      "17000/17000 [==============================] - 0s 8us/sample - loss: 0.3144 - mean_squared_error: 0.3144\n",
      "Epoch 101/140\n",
      "17000/17000 [==============================] - 0s 8us/sample - loss: 0.3143 - mean_squared_error: 0.3143\n",
      "Epoch 102/140\n",
      "17000/17000 [==============================] - 0s 9us/sample - loss: 0.3148 - mean_squared_error: 0.3148\n",
      "Epoch 103/140\n",
      "17000/17000 [==============================] - 0s 13us/sample - loss: 0.3151 - mean_squared_error: 0.3151\n",
      "Epoch 104/140\n",
      "17000/17000 [==============================] - 0s 11us/sample - loss: 0.3155 - mean_squared_error: 0.3155\n",
      "Epoch 105/140\n",
      "17000/17000 [==============================] - 0s 10us/sample - loss: 0.3159 - mean_squared_error: 0.3159\n",
      "Epoch 106/140\n",
      "17000/17000 [==============================] - 0s 8us/sample - loss: 0.3144 - mean_squared_error: 0.3144\n",
      "Epoch 107/140\n",
      "17000/17000 [==============================] - 0s 8us/sample - loss: 0.3146 - mean_squared_error: 0.3146\n",
      "Epoch 108/140\n",
      "17000/17000 [==============================] - 0s 8us/sample - loss: 0.3141 - mean_squared_error: 0.3141\n",
      "Epoch 109/140\n",
      "17000/17000 [==============================] - 0s 11us/sample - loss: 0.3143 - mean_squared_error: 0.3143\n",
      "Epoch 110/140\n",
      "17000/17000 [==============================] - 0s 11us/sample - loss: 0.3141 - mean_squared_error: 0.3141\n",
      "Epoch 111/140\n",
      "17000/17000 [==============================] - 0s 10us/sample - loss: 0.3135 - mean_squared_error: 0.3135\n",
      "Epoch 112/140\n",
      "17000/17000 [==============================] - 0s 8us/sample - loss: 0.3153 - mean_squared_error: 0.3153\n",
      "Epoch 113/140\n",
      "17000/17000 [==============================] - 0s 8us/sample - loss: 0.3134 - mean_squared_error: 0.3134\n",
      "Epoch 114/140\n",
      "17000/17000 [==============================] - 0s 11us/sample - loss: 0.3141 - mean_squared_error: 0.3141\n",
      "Epoch 115/140\n",
      "17000/17000 [==============================] - 0s 10us/sample - loss: 0.3145 - mean_squared_error: 0.3145\n",
      "Epoch 116/140\n",
      "17000/17000 [==============================] - 0s 9us/sample - loss: 0.3148 - mean_squared_error: 0.3148\n",
      "Epoch 117/140\n",
      "17000/17000 [==============================] - 0s 8us/sample - loss: 0.3144 - mean_squared_error: 0.3144\n",
      "Epoch 118/140\n",
      "17000/17000 [==============================] - 0s 9us/sample - loss: 0.3137 - mean_squared_error: 0.3137\n",
      "Epoch 119/140\n",
      "17000/17000 [==============================] - 0s 9us/sample - loss: 0.3136 - mean_squared_error: 0.3136\n",
      "Epoch 120/140\n",
      "17000/17000 [==============================] - 0s 9us/sample - loss: 0.3137 - mean_squared_error: 0.3137\n",
      "Epoch 121/140\n",
      "17000/17000 [==============================] - 0s 9us/sample - loss: 0.3141 - mean_squared_error: 0.3141\n",
      "Epoch 122/140\n",
      "17000/17000 [==============================] - 0s 8us/sample - loss: 0.3138 - mean_squared_error: 0.3138\n",
      "Epoch 123/140\n",
      "17000/17000 [==============================] - 0s 9us/sample - loss: 0.3139 - mean_squared_error: 0.3139\n",
      "Epoch 124/140\n",
      "17000/17000 [==============================] - 0s 11us/sample - loss: 0.3128 - mean_squared_error: 0.3128\n",
      "Epoch 125/140\n",
      "17000/17000 [==============================] - 0s 11us/sample - loss: 0.3127 - mean_squared_error: 0.3127\n",
      "Epoch 126/140\n",
      "17000/17000 [==============================] - 0s 11us/sample - loss: 0.3132 - mean_squared_error: 0.3132\n",
      "Epoch 127/140\n",
      "17000/17000 [==============================] - 0s 10us/sample - loss: 0.3128 - mean_squared_error: 0.3128\n",
      "Epoch 128/140\n",
      "17000/17000 [==============================] - 0s 8us/sample - loss: 0.3132 - mean_squared_error: 0.3132\n",
      "Epoch 129/140\n",
      "17000/17000 [==============================] - 0s 9us/sample - loss: 0.3135 - mean_squared_error: 0.3135\n",
      "Epoch 130/140\n",
      "17000/17000 [==============================] - 0s 10us/sample - loss: 0.3129 - mean_squared_error: 0.3129\n",
      "Epoch 131/140\n",
      "17000/17000 [==============================] - 0s 9us/sample - loss: 0.3131 - mean_squared_error: 0.3131\n",
      "Epoch 132/140\n",
      "17000/17000 [==============================] - 0s 9us/sample - loss: 0.3127 - mean_squared_error: 0.3127\n",
      "Epoch 133/140\n",
      "17000/17000 [==============================] - 0s 8us/sample - loss: 0.3128 - mean_squared_error: 0.3128\n",
      "Epoch 134/140\n",
      "17000/17000 [==============================] - 0s 11us/sample - loss: 0.3130 - mean_squared_error: 0.3130\n",
      "Epoch 135/140\n",
      "17000/17000 [==============================] - 0s 10us/sample - loss: 0.3127 - mean_squared_error: 0.3127\n",
      "Epoch 136/140\n",
      "17000/17000 [==============================] - 0s 9us/sample - loss: 0.3124 - mean_squared_error: 0.3124\n",
      "Epoch 137/140\n",
      "17000/17000 [==============================] - 0s 9us/sample - loss: 0.3125 - mean_squared_error: 0.3125\n",
      "Epoch 138/140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17000/17000 [==============================] - 0s 9us/sample - loss: 0.3127 - mean_squared_error: 0.3127\n",
      "Epoch 139/140\n",
      "17000/17000 [==============================] - 0s 10us/sample - loss: 0.3130 - mean_squared_error: 0.3130\n",
      "Epoch 140/140\n",
      "17000/17000 [==============================] - 0s 11us/sample - loss: 0.3130 - mean_squared_error: 0.3130s - loss: 0.3151 - mean_squared_error: 0.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Evaluate the new model against the test set:\n",
      "3000/3000 [==============================] - 0s 149us/sample - loss: 0.3641 - mean_squared_error: 0.3641\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3641389807065328, 0.364139]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The following variables are the hyperparameters.\n",
    "learning_rate = 0.007\n",
    "epochs = 140\n",
    "batch_size = 1000\n",
    "\n",
    "# Specify the label\n",
    "label_name = \"median_house_value\"\n",
    "\n",
    "# Establish the model's topography.\n",
    "my_model = create_model(learning_rate, my_feature_layer)\n",
    "\n",
    "# Train the model on the normalized training set. We're passing the entire\n",
    "# normalized training set, but the model will only use the features\n",
    "# defined by the feature_layer.\n",
    "epochs, mse = train_model(my_model, train_df_norm, epochs, \n",
    "                          label_name, batch_size)\n",
    "plot_the_loss_curve(epochs, mse)\n",
    "\n",
    "# After building a model against the training set, test that model\n",
    "# against the test set.\n",
    "test_features = {name:np.array(value) for name, value in test_df_norm.items()}\n",
    "test_label = np.array(test_features.pop(label_name)) # isolate the label\n",
    "print(\"\\n Evaluate the new model against the test set:\")\n",
    "my_model.evaluate(x = test_features, y = test_label, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the hyperparameters set like so, our deep neural network significantly outperforms our linear regression model. We can further tune the neural network via hyperparameters and adjusting the number of nodes and layers until we find a more optimal performance, if we have the time and the inclination to do so.\n",
    "\n",
    "---------------------\n",
    "\n",
    "### 5. Conclusion\n",
    "\n",
    "##### 5.1 Conclusion\n",
    "\n",
    "In this project, we successfully built a deep neural network using TensorFlow and Keras, and produced better quality predictions than were possible using a simpler Linear Regression algorithm.\n",
    "\n",
    "Thanks to Tensorflow and Keras, the actual code required to build a neural network model is not significantly more complex than that required for a [linear regression](https://github.com/thecraigd/Linear_Regression_with_TensorFlow), but the computations happening under the hood are.\n",
    "\n",
    "We also used some simple [feature engineering](https://en.wikipedia.org/wiki/Feature_engineering) by implementing a feature cross using latitude and longitude. This same method can be utilised to cross multiple features and to create more complex new features, so this was very useful.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
